{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba70ad9d",
   "metadata": {},
   "outputs": [],
   "source": [
    "!pip install vit-pytorch\n",
    "!pip install timm\n",
    "!pip install torch==1.11.0+cu113 torchvision==0.12.0+cu113 -f https://download.pytorch.org/whl/torch_stable.html"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f4055695",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "#os.environ['KMP_DUPLICATE_LIB_OK']='True'\n",
    "from PIL import Image\n",
    "import time\n",
    "import torch\n",
    "import torchvision\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from vit_pytorch import ViT\n",
    "import albumentations\n",
    "import albumentations.pytorch\n",
    "from torch.utils.data import Dataset, DataLoader, SubsetRandomSampler\n",
    "from torchvision import transforms, models, transforms\n",
    "from matplotlib import pyplot as plt\n",
    "import cv2\n",
    "import numpy as np\n",
    "import copy\n",
    "import time\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import precision_recall_fscore_support\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from collections import defaultdict\n",
    "import timm\n",
    "from scipy.special import softmax\n",
    "from sklearn.model_selection import KFold, StratifiedKFold"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d828d498",
   "metadata": {},
   "outputs": [],
   "source": [
    "BASE = \"/Classification/data/\"\n",
    "path_to_images =  BASE + \"remove_background/\" \n",
    "SEGMENT = \"body\"\n",
    "CLASSIFIER = 'vit'\n",
    "path_for_models = BASE + \"models/\"\n",
    "path_to_save_values = BASE + \"remove_background/results/\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ca59c571",
   "metadata": {},
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "device"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9a48676d",
   "metadata": {},
   "outputs": [],
   "source": [
    "timm.list_models('*vit*')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6778ca62",
   "metadata": {},
   "outputs": [],
   "source": [
    "# processing dataset metadata\n",
    "def process_dataset_meta_info(path, part):\n",
    "    true_files = []\n",
    "    true_file_paths = os.listdir(path + 'WFT_' + part + '/' )\n",
    "    true_file_paths.sort()\n",
    "    for item in true_file_paths:\n",
    "        if item[-4:] == \".png\" or item[-4:] == \".jpg\":\n",
    "            true_files.append(path + 'WFT_' + part + '/'  + item)\n",
    "    true_labels = [1]*len(true_files)\n",
    "\n",
    "    negative_files = []\n",
    "    negative_file_paths = os.listdir(path + 'NOTWFT_' + part + '/' )\n",
    "    negative_file_paths.sort()\n",
    "    for item in negative_file_paths:\n",
    "        if item[-4:] == \".png\" or item[-4:] == \".jpg\":\n",
    "            negative_files.append(path + 'NOTWFT_' + part + '/' + item)\n",
    "    negative_labels = [0]*len(negative_files)\n",
    "    \n",
    "    files = true_files + negative_files\n",
    "    labels = true_labels + negative_labels\n",
    "    data_list = []\n",
    "    \n",
    "    print('len.......', len(files))\n",
    "    for idx in range(0, len(files)):\n",
    "        data = {'file_path': files[idx],\n",
    "                'label' : labels[idx]}\n",
    "        data_list.append(data)\n",
    "    \n",
    "    data_list = np.array(data_list)\n",
    "    return data_list # change the return of the original function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "844d7114",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reading thrip dataset\n",
    "class ThripDataset(Dataset):\n",
    "    def __init__(self, file_paths, labels, is_train, required_transform=None, optional_transform=None):\n",
    "        self.file_paths = file_paths\n",
    "        self.labels = labels\n",
    "        self.required_transform = required_transform\n",
    "        self.optional_transform = optional_transform\n",
    "        self.is_train = is_train\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.file_paths)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        label = self.labels[idx] # extract the label\n",
    "        file_path = self.file_paths[idx] # extract the filepath\n",
    "        #image = Image.open(file_path) # read the image with PIL\n",
    "        image = cv2.imread(file_path)\n",
    "        image = cv2.cvtColor(image, cv2.COLOR_BGR2RGB)\n",
    "        \n",
    "        if self.optional_transform and self.is_train:\n",
    "            image = self.optional_transform(image=image)['image']\n",
    "\n",
    "        if self.required_transform:\n",
    "            image = self.required_transform(image)\n",
    "        \n",
    "        data_sample = {'x': image, 'y': label, 'id' : file_path[-7:-4]} # added id to the data_sample\n",
    "        \n",
    "        return data_sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d54fb2f",
   "metadata": {},
   "outputs": [],
   "source": [
    "def evaluate(y_true, y_pred):\n",
    "    acc = accuracy_score(y_true, y_pred)\n",
    "    p, r, f, _ = precision_recall_fscore_support(y_true, y_pred, average = \"macro\")\n",
    "    mat = confusion_matrix(y_true, y_pred)\n",
    "\n",
    "    print(\"accuracy:\", acc)\n",
    "    print(\"precision:\", p)\n",
    "    print(\"recall:\", r)\n",
    "    print(\"f-score:\", f)\n",
    "    print(\"confusion matrix:\")\n",
    "    print(mat, '\\n')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bbc5f14",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, criterion, optimizer, scheduler, dataloaders, class_names, dataset_size, num_epochs=25):\n",
    "    since = time.time()\n",
    "    dataloaders = dataloaders\n",
    "    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "    best_model = copy.deepcopy(model)\n",
    "    best_acc = 0.0\n",
    "    best_train_loss = 1000000\n",
    "    best_loss = 1000000\n",
    "    loss_vals= defaultdict(lambda: [])\n",
    "    acc_vals= defaultdict(lambda: [])\n",
    "    count = 0\n",
    "\n",
    "    for epoch in range(num_epochs):\n",
    "        print('Epoch {}/{}'.format(epoch, num_epochs - 1))\n",
    "        print('-' * 10)\n",
    "\n",
    "        # Each epoch has a training and validation phase\n",
    "        for phase in ['train', 'test']:\n",
    "            if phase == 'train':\n",
    "                model.train()  # Set model to training mode\n",
    "            else:\n",
    "                model.eval()   # Set model to evaluate mode\n",
    "\n",
    "            running_loss = 0.0\n",
    "            running_corrects = 0\n",
    "\n",
    "            # Iterate over data.\n",
    "            for data in dataloaders[phase]:\n",
    "                inputs = data['x'].to(device)\n",
    "                labels = data['y'].to(device).long()\n",
    "\n",
    "                # zero the parameter gradients\n",
    "                optimizer.zero_grad()\n",
    "\n",
    "                # forward\n",
    "                # track history if only in train\n",
    "                with torch.set_grad_enabled(phase == 'train'):\n",
    "                    outputs = model(inputs)\n",
    "                    _, preds = torch.max(outputs, 1)\n",
    "                    loss = criterion(outputs, labels)\n",
    "\n",
    "                    # backward + optimize only if in training phase\n",
    "                    if phase == 'train':\n",
    "                        loss.backward()\n",
    "                        optimizer.step()\n",
    "\n",
    "                # statistics\n",
    "                running_loss += loss.item() * inputs.size(0)\n",
    "                running_corrects += torch.sum(preds == labels.data)\n",
    "                \n",
    "            if phase == 'train':\n",
    "                scheduler.step()\n",
    "\n",
    "            epoch_loss = running_loss / dataset_size[phase]\n",
    "            epoch_acc = running_corrects.double() / dataset_size[phase]\n",
    "\n",
    "            print('{} Loss: {:.4f} Acc: {:.4f}'.format(\n",
    "                phase, epoch_loss, epoch_acc))\n",
    "            loss_vals[phase].append(epoch_loss)\n",
    "            acc_vals[phase].append(epoch_acc)\n",
    "            \n",
    "            # deep copy the model\n",
    "            if phase == 'test' and count == 0:\n",
    "                best_acc = epoch_acc\n",
    "                \n",
    "                \n",
    "            if phase == \"train\":\n",
    "                if best_train_loss > epoch_loss:\n",
    "                    best_train_loss = epoch_loss\n",
    "                    best_loss = epoch_loss\n",
    "                    print(\".........update ...\", epoch)\n",
    "                    best_model_wts = copy.deepcopy(model.state_dict())\n",
    "                    best_model = copy.deepcopy(model)\n",
    "                    count = 0\n",
    "                else:\n",
    "                    count += 1\n",
    "\n",
    "            \n",
    "    time_elapsed = time.time() - since\n",
    "    print('Training complete in {:.0f}m {:.0f}s'.format(\n",
    "        time_elapsed // 60, time_elapsed % 60))\n",
    "    \n",
    "    # load best model weights\n",
    "    model.load_state_dict(best_model_wts)\n",
    "    \n",
    "    outputs = []\n",
    "    labels = []\n",
    "    idx = []\n",
    "    outputs_tr = []\n",
    "    labels_tr = []\n",
    "    idx_tr = []\n",
    "    \n",
    "    for data in dataloaders[\"test\"]:\n",
    "        inputs = data['x'].to(device)\n",
    "        labels.extend(data['y'].to(device).long())\n",
    "        print('*****************', len(labels))\n",
    "        idx.extend(data['id'])\n",
    "        outputs.extend(best_model(inputs))\n",
    "        \n",
    "        \n",
    "    for data in dataloaders[\"train\"]:\n",
    "        inputs_tr = data['x'].to(device)\n",
    "        labels_tr.extend(data['y'].to(device).long())\n",
    "        idx_tr.extend(data['id'])\n",
    "        outputs_tr.extend(best_model(inputs_tr))\n",
    "        \n",
    "    return best_model, outputs, labels, idx, outputs_tr, labels_tr, idx_tr, loss_vals, acc_vals"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6b349665",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_values_to_files(file, description, list1, list2 = None, list3 = None):\n",
    "    f=open(file, \"w+\")\n",
    "    f.write(description + '\\n')\n",
    "    \n",
    "    if list2 == None:\n",
    "        for d1 in list1:\n",
    "            if not isinstance(d1, str):\n",
    "                pass\n",
    "                d1 = d1.detach().cpu().numpy()\n",
    "            f.write(str(d1) + '\\n')\n",
    "    \n",
    "    if list2 != None:\n",
    "        for d1, d2, d3 in zip(list1, list2, list3):\n",
    "                d1 = d1.detach().cpu().numpy()  \n",
    "                if not isinstance(d2, int):\n",
    "                    d2 = d2.detach().cpu().numpy()\n",
    "                d3 = d3\n",
    "                f.write(str(d1[0]) + ', ' + str(d1[1]) + ', ' + str(d2) + ', ' + str(d3) + '\\n')        \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b056f466",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_acc_loss_to_files(file, description, list1, list2):\n",
    "    f=open(file, \"w+\")\n",
    "    f.write(description + '\\n')\n",
    "    count = 0\n",
    "    for (d1, d2 , d3, d4) in zip(list1['train'], list2['train'], list1['test'], list2['test']):\n",
    "        d2 = d2.detach().cpu().numpy()\n",
    "        d4 = d4.detach().cpu().numpy()\n",
    "        f.write(str(count) + ', ' + str(d1) + ', ' + str(d2) + ', ' + str(d3) + ', ' + str(d4)+ '\\n')\n",
    "        count = count + 1\n",
    "            \n",
    "    f.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b0a3cc76",
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_data(path, filename):\n",
    "    f = open(path + filename, 'r')\n",
    "    f.readline()\n",
    "    \n",
    "    predictions = []\n",
    "    labels = []\n",
    "    for line in f:\n",
    "        print(line)\n",
    "        splits = line.strip().split(']')\n",
    "        #print(splits[-1])\n",
    "        labels.append(int(splits[-1].split(',')[-1]))\n",
    "        if len(splits[0].split()) > 2:\n",
    "            preds = [float(splits[0].split()[1]), float(splits[0].split()[-1])] \n",
    "        else:\n",
    "            preds = [float(splits[0].split()[0].split('[')[-1]), float(splits[0].split()[-1])]\n",
    "        #print(preds, softmax(np.array(preds))[1])\n",
    "        predictions.append(softmax(np.array(preds))[1])\n",
    "    # print(\"=============================\")\n",
    "    return labels, predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c16ffd5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def create_model(model = 'vit_base_patch16_384', optimizer = 'ADAM', lr = 0.01, step_size = 10):\n",
    "    model_ft = timm.create_model( model, pretrained=True, num_classes=2)\n",
    "    model_ft = model_ft.to(device)\n",
    "    \n",
    "    for param in model_ft.parameters():\n",
    "        param.requires_grad = False\n",
    "    \n",
    "    for param in model_ft.blocks[11].parameters():\n",
    "        param.requires_grad = False\n",
    "\n",
    "    for param in model_ft.head.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    criterion = torch.nn.CrossEntropyLoss()\n",
    "    \n",
    "    if optimizer == 'ADAM':\n",
    "        optimizer_ft = optim.Adam(model_ft.parameters(), lr=lr)\n",
    "    else: \n",
    "        optimizer_ft = optim.SGD(model_ft.parameters(), lr, momentum = 0.9)\n",
    "        \n",
    "    exp_lr_scheduler = optim.lr_scheduler.StepLR(optimizer_ft, step_size=step_size, gamma=0.1)\n",
    "    \n",
    "    return model_ft, optimizer_ft, criterion , exp_lr_scheduler  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ef370567",
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_the_model(image_path, segment, batch_size, num_epochs, lr, step_size):\n",
    "    # defining data augmentation and transforms\n",
    "    optional_transforms = albumentations.Compose([\n",
    "                          albumentations.HorizontalFlip(),\n",
    "                          albumentations.VerticalFlip(), \n",
    "                          ])\n",
    "    \n",
    "    required_transforms = transforms.Compose([\n",
    "                          transforms.ToPILImage(),\n",
    "                          transforms.Resize((384, 384)),\n",
    "                          transforms.ToTensor()\n",
    "                          ])\n",
    "\n",
    "    print('Path {}'.format(image_path))\n",
    "    data = process_dataset_meta_info(image_path, segment)\n",
    "    print(len(data))\n",
    " \n",
    "    kf = StratifiedKFold(n_splits=5, shuffle= True, random_state = 8)\n",
    "    #...............\n",
    "    labels_for_spliter = [d['label'] for d in data]\n",
    "    print( labels_for_spliter)\n",
    "    #......................\n",
    "    \n",
    "    for fold, (train_idx, test_idx) in enumerate(kf.split(np.arange(len(data)), labels_for_spliter)):\n",
    "        \n",
    "        print('Fold {}'.format(fold+1))\n",
    "        train_sampler = data[train_idx]\n",
    "        test_sampler = data[test_idx]\n",
    "        \n",
    "        np.random.seed(8)\n",
    "        np.random.shuffle(train_sampler)\n",
    "        np.random.shuffle(test_sampler)\n",
    "    \n",
    "        train_file_paths = []\n",
    "        train_labels = []\n",
    "        test_file_paths = []\n",
    "        test_labels = []\n",
    "        \n",
    "        for i, sample in enumerate(train_sampler):\n",
    "            train_file_paths.append(sample['file_path'])\n",
    "            train_labels.append(sample['label'])\n",
    "        \n",
    "        for i, sample in enumerate(test_sampler):\n",
    "            test_file_paths.append(sample['file_path'])\n",
    "            test_labels.append(sample['label'])\n",
    "            \n",
    "        train_dataset = ThripDataset(file_paths=train_file_paths, labels=train_labels, is_train = True, optional_transform = optional_transforms, required_transform = required_transforms)\n",
    "        test_dataset = ThripDataset(file_paths=test_file_paths, labels=test_labels, is_train = False, optional_transform = optional_transforms, required_transform = required_transforms)\n",
    "        \n",
    "        if batch_size == None:\n",
    "            batch_size = round(train_dataset.__len__()/5)\n",
    "        \n",
    "        train_dataloader = DataLoader(train_dataset, batch_size = batch_size, shuffle = False, num_workers = 0)\n",
    "        test_dataloader = DataLoader(test_dataset, batch_size = batch_size)\n",
    "        \n",
    "        dataloaders = {'train': train_dataloader, 'test': test_dataloader}\n",
    "        dataset_size = {'train': len(train_dataset), 'test': len(test_dataset)}\n",
    "        class_names = ['NOTWFT', 'WFT']\n",
    "        \n",
    "\n",
    "        model_ft, optimizer_ft, criterion, exp_lr_scheduler = create_model(model = 'vit_base_patch16_384', optimizer = 'ADAM', lr = lr, step_size = step_size)\n",
    "        model_ft = model_ft.to(device)\n",
    "        model, outputs, labels, idx, outputs_tr, labels_tr, idx_tr, loss_vals, acc_vals = train_model(model_ft, criterion, optimizer_ft, exp_lr_scheduler, dataloaders, class_names,dataset_size, num_epochs)\n",
    "        root = path_to_save_values + SEGMENT + '_' + str(fold) + '_' + str(step_size)\n",
    "        save_values_to_files(root + '_test.txt', 'test_outputs, labels, id', outputs, labels, idx)\n",
    "        save_values_to_files(root + '_train.txt', 'train_outputs, labels, id', outputs_tr, labels_tr, idx_tr)\n",
    "        save_acc_loss_to_files(root + '_lossAcc.txt', 'ephoc, train_loss, train_acc, test_loss, test_acc', loss_vals, acc_vals)\n",
    "        torch.save(model.state_dict(), path_for_models + SEGMENT + \"_vit_base_patch16_384\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c429cbae",
   "metadata": {},
   "outputs": [],
   "source": [
    "run_the_model(image_path = path_to_images, segment = SEGMENT, batch_size = 40, num_epochs = 30, lr = 0.01, step_size= 10)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "py39",
   "language": "python",
   "name": "py39"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
